[1mdiff --git a/NIPS14/greedy.tex b/NIPS14/greedy.tex[m
[1mindex ed62697..6151722 100755[m
[1m--- a/NIPS14/greedy.tex[m
[1m+++ b/NIPS14/greedy.tex[m
[36m@@ -1,5 +1,5 @@[m
% greedy[m
To solve the non-convex problem in Eq. (\ref{eq:greedyUnified}) and find its optimal solution, we propose a greedy learning algorithm by successively adding rank-1 estimation of the mode-n unfolding. The main idea of the algorithm is to unfold the tensor into a matrix,  seek for its rank-1 approximation and then fold back into a tensor with same dimensionality. We describe this algorithm in three steps: (i) First, we show that we can learn rank-1 matrix estimations efficiently by solving a generalized eigenvalue problem, (ii) We use the rank-1 matrix estimation to greedily solve the original tensor rank constrained problem, and (iii) We propose an enhancement [31m[-by-][m[32m{+via+}[m orthogonal projections after each greedy step.

\paragraph{Optimal rank-1 Matrix Learning} %After we have a unified formulation of our learning tasks in Eq. (\ref{eq:greedyUnified}), we specify the greedy updates for solving it. [m
The following lemma enables us to find such optimal rank-1 estimation of the matrices.[m
[36m@@ -25,11 +25,11 @@[m [mand $\widehat{\mathbf{u}}$ can be computed as[m
\end{align}[m
\end{lemma}[m

Proof is deferred to[31m[-the-][m Appendix \ref{sec:optRank1}. Eq. (\ref{eq:solv}) is a generalized eigenvalue problem whose dominant eigenvector can be found efficiently \cite{jpen2000}. If $XX^{\top}$ is full rank, as [31m[-we will assume-][m[32m{+assumed+}[m in Theorem \ref{thm:greedy}, the problem is simplified to [31m[-the-][m[32m{+a+}[m  regular eigenvalue problem whose dominant eigenvector can be efficiently computed.
%which can be solved in $\mathcal{O}(n_z\log(p))$ iterations if the matrix has $n_z$ non-zero elements \cite{Kuczynski1992}.  [m

\paragraph{Greedy Low n-rank Tensor Learning} The optimal rank-1 matrix learning serves as a basic element in our greedy algorithm. [m
Using Lemma \ref{lem:rank1opt}, we can solve the problem in Eq. (\ref{eq:greedyUnified}) in the \textit{Forward Greedy Selection} framework as follows:  at each iteration of the greedy algorithm, it searches for the mode that gives the largest decrease in the objective function. It does so by unfolding the tensor in that mode and finding the best rank-1 estimation of the unfolded tensor. After finding the optimal mode, it adds the rank-1 estimate in that mode to the current estimation of the tensor. [31m[-Denoting-][m[32m{+Algorithm \ref{alg:greedy} shows the details of this approach, where+}[m $\loss(\W;\Y, \V ) = \sum_{m=1}^{M} \|\W_{:, :, m}\Y_{:, :, m} - \V_{:, :, m} [31m[-\|^2_F$, Algo. \ref{alg:greedy} shows the details of this approach.-][m[32m{+\|^2_F$.+}[m  Note that we can find the optimal rank-1 solution in only one of the modes, but it is enough to guarantee the convergence of our greedy algorithm. %rate in Theorem \ref{thm:greedy}.
% Due to the page limit, a detailed example of sub-problem in each fold is described in Appendix \ref{sec:gfolding}.[m

\begin{algorithm}[t][m
[36m@@ -70,7 +70,7 @@[m [m$\Delta_n\gets \loss(\W;\Y, \V ) -  \loss(\mathrm{refold}(\W_{(n)}+B_n);\Y, \V )[m
\end{algorithmic}[m
\end{algorithm}}[m

Theorem \ref{thm:greedy} bounds the difference between the loss function evaluated at each iteration of the greedy algorithm and the [32m{+one at the+}[m globally optimal solution.

\begin{theorem}\label{thm:greedy}[m
Suppose in Eq. (\ref{eq:greedyUnified}) the matrices $\Y_{:, :, m}^{\top}\Y_{:, :, m}$ for $m = 1, \ldots, M$ are positive definite.  The solution of Algo. \ref{alg:greedy} at its $k$th iteration step satisfies the following inequality:[m
[36m@@ -80,9 +80,9 @@[m [mSuppose in Eq. (\ref{eq:greedyUnified}) the matrices $\Y_{:, :, m}^{\top}\Y_{:,[m
\noindent where $\W^*$ is the global minimizer of the problem in Eq. (\ref{eq:greedyUnified}) and $\| \Y\|_{2}$ is the largest singular value of a block diagonal matrix created by placing the matrices $\Y(:, :, m)$ on its diagonal blocks.[m
\end{theorem}[m

The detailed proof is given in Appendix \ref{sec:gProof}. The key idea of the proof is that the amount of decrease in the loss function by each step in the selected mode is not smaller than the amount of decrease if we had selected the first mode. The theorem shows that we can obtain the same rate of convergence for learning low rank tensors as achieved in \cite{ShalevShwartz2010} for learning low rank matrices. The greedy algorithm in [31m[-Algo.-][m[32m{+Algorithm+}[m \ref{alg:greedy} is also connected to[31m[-the-][m mixture regularization in \cite{tomioka2010estimation}: the mixture approach decomposes the solution into a set of low rank structures while the greedy algorithm successively learns a set of rank one components. 

\paragraph{Greedy Algorithm with Orthogonal Projections} It is well-known that the forward greedy algorithm may make steps in sub-optimal directions because of noise.  A common solution to alleviate the effect of noise is to make orthogonal projections after each greedy [31m[-step, see for e.g.-][m[32m{+step+}[m \cite{Barron2008,Shwartz11}. Thus, we enhance the forward greedy algorithm by projecting the solution into the space spanned by the singular vectors of its mode-1 unfolding. The  greedy algorithm with \textit{orthogonal} projections performs an extra step in line 13 of [31m[-Algo.-][m[32m{+Algorithm+}[m \ref{alg:greedy}:  It finds the top $k$ singular vectors of the solution: $[U, S, V] \gets \mathrm{svd}(\mathcal{W}_{(1)}, k)$ where $k$ is the iteration number. Then it finds the best solution in the space spanned by $U$ and $V$ by solving $\widehat{S} \gets \min_{S}\loss(USV^{\top}, \Y, \V)$ which has a closed form solution. Finally, it reconstructs the solution: $\W \gets \mathrm{refold}(U\widehat{S}V^{\top}, 1)$. Note that the projection only needs to find top $k$ singular vectors which can be computed efficiently for small values of $k$.



