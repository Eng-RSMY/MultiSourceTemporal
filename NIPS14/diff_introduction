[1mdiff --git a/NIPS14/introduction.tex b/NIPS14/introduction.tex[m
[1mindex 7f59847..dea182f 100755[m
[1m--- a/NIPS14/introduction.tex[m
[1m+++ b/NIPS14/introduction.tex[m
[36m@@ -1,19 +1,20 @@[m
%introduction[m
Spatio-temporal data provide unique information regarding ``where'' and ``when'', which is essential to answer many important  questions in scientific studies from geology, climatology to sociology. [31m[-From a machine learning perspective,-][m[32m{+In the context of big data,+}[m we are confronted with a series of new challenges when analyzing spatio-temporal data because of the complex spatial and temporal dependencies involved. 

A plethora of excellent work has been conducted to address the challenge and achieved successes to a certain [31m[-extent, see e.g.-][m[32m{+extent+}[m  \cite{cressie2010fixed, [31m[-isaaks2011applied} and the references therein.-][m[32m{+isaaks2011applied}.+}[m Often times, geostatistical models use cross variogram and cross covariance functions to describe the intrinsic dependency structure. However, the parametric form of[31m[-the-][m cross variogram and[31m[-the-][m cross covariance functions impose strong assumptions on the [31m[-correlation among the data. Moreover, choosing a valid variogram function-][m[32m{+spatial and temporal correlation, which+}[m requires domain knowledge and manual work. [31m[-Most importantly,-][m[32m{+Furthermore,+}[m parameter learning of those statistical models is computationally expensive, making them infeasible for  large-scale[31m[-spatio-temporal-][m applications. 

Cokriging and forecasting are[31m[-the-][m two central tasks in multivariate spatio-temporal analysis. Cokriging utilizes the spatial correlations to predict the value of the variables for new locations. One widely adopted method is  [31m[-the  Multitask-][m[32m{+multitask+}[m Gaussian [31m[-Process-][m[32m{+process+}[m (MTGP) \cite{bonilla2007multi}, which assumes [31m[-the-][m[32m{+a+}[m Gaussian process prior 
[31m[-on the observations.-][m[32m{+over latent functions to directly induce correlations between tasks.+}[m However, for a cokriging task with $M$ variables of $P$ locations for $T$ time stamps, the time complexity of MTGP is [31m[-$\mathcal{O}(M^3P^3T)$.-][m[32m{+$\mathcal{O}(M^3P^3T)$ \cite{}.+}[m 
%Acceleration techniques such as Nystr{\"o}m method and incomplete-Cholesky decomposition are employed, but they do not fully capture the correlations. [m
For forecasting,  popular methods in multivariate time series analysis include[31m[-the-][m  vector autoregressive (VAR) [31m[-model, the-][m[32m{+models,+}[m autoregressive integrated moving average (ARIMA) [31m[-model,-][m[32m{+models,+}[m and cointegration models. [32m{+An alternative method for spatio-temporal analysis  is+}[m Bayesian hierarchical spatio-temporal models [31m[-have studied both space-time-][m[32m{+with either+}[m  separable and non-separable [32m{+space-time+}[m covariance functions \cite{cressie1999classes}. Rank reduced models have been proposed to [31m[-incorporate-][m[32m{+capture+}[m the [31m[-interrelationship-][m[32m{+inter-dependency+}[m among variables \cite{anderson1951estimating}. However, [31m[-none of the existing work handles-][m[32m{+very few models can directly handle+}[m the [31m[-commonalities-][m[32m{+correlations+}[m among variables, space and time simultaneously in a scalable way. In this paper, we aim to address this problem by presenting a unified framework for many spatio-temporal analysis tasks that are scalable for large-scale applications. % without assuming the explicit form of the commonalities among those dimensions. 

%Since the multivariate spatio-temporal data come in the form of (variable $\times$ time $\times$ location), it is natural to represent it using tensors. [m
Tensor representation provides a convenient way to [31m[-incorporate the-][m[32m{+capture+}[m inter-dependencies along multiple dimensions. Therefore it is natural to represent the multivariate spatio-temporal data  in tensor.  Recent advances in low rank learning have led to simple models that can  capture the commonalities among each mode of the tensor [31m[-and produce simpler models, which are easier to learn.-][m[32m{+\cite{}.+}[m Similar [31m[-assumptions-][m[32m{+argument+}[m can be [31m[-seen-][m[32m{+found+}[m in the literature of spatial data recovery \cite{gandy2011tensor}, neuroimaging analysis \cite{zhou2013tensor}, and  multi-task learning \cite{romera2013multilinear}. Our work builds upon[31m[-the-][m  recent advances in low rank tensor learning \cite{kolda2009tensor, gandy2011tensor, zhou2013tensor} and further considers the scenario where additional side information [31m[-for the-][m[32m{+of+}[m data is available. For [31m[-the-][m[32m{+example, in+}[m geo-spatial applications, apart from measurements of multiple variables,[31m[-we also utilize the-][m  geographical [31m[-information. For-][m[32m{+information is available to infer location adjacency; in+}[m social network applications,[31m[-we take advantage of the-][m  friendship network [31m[-structure.-][m[32m{+structure is collected to obtain preference similarity.+}[m  To utilize the side information, we [32m{+can+}[m construct [31m[-similarity kernel based on them and regularize with the corresponding-][m[32m{+a+}[m Laplacian [31m[-matrix,-][m[32m{+regularizer from the similarity matrices,+}[m which favors locally smooth solutions.

We develop a fast greedy algorithm for learning low rank tensors based on the greedy structure learning framework \cite{Barron2008,Zhang2011,Shwartz11}.  [m
[31m[-The greedy-][m[32m{+Greedy+}[m low rank tensor learning is efficient, as it does not require full singular value decomposition of large matrices as opposed to other alternating direction [31m[-methods.-][m[32m{+methods \cite{refs for alternating direction methods}.+}[m 
We also provide a bound on the difference between the loss function at [31m[-the-][m[32m{+our+}[m greedy[31m[-algorithm-][m solution and the [32m{+one at the+}[m globally optimal solution. %\ryedit{Singular value statement is too technical for introduction. What is the condition for global optimality.}
 Finally, we present [31m[-simulation-][m[32m{+experiment+}[m results [32m{+on simulation datasets+}[m as well as [31m[-the empirical evaluation results on-][m[32m{+application datasets in+}[m  climate and social network [31m[-data where-][m[32m{+analysis, which shows that+}[m our algorithm [32m{+is faster and+}[m achieves higher [32m{+prediction+}[m accuracy[31m[-with increased speed-][m than state-of-art approaches in cokriging and forecasting tasks.

%\ryedit{We don't need separate notation paragraph, introduce when first appear}[m
%\paragraph{Notations} In this paper, we use lowercase letter for scalers, bold font small letter for vectors, capital letter for matrices and calligraphic font for tensors. We describe the tensor basics and notations to be used in this paper. [m
